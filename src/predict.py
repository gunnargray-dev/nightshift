"""Predictive analytics — Session 16.

``awake predict`` analyses historical session data from AWAKE_LOG.md
and the live codebase to produce a ranked list of focus areas for the *next*
session.

The prediction engine uses five signals:

1. **Module age** — modules not touched in recent sessions score higher.
2. **Health trend** — modules with declining health scores get priority.
3. **Coverage weakness** — modules with low test coverage rise to the top.
4. **Complexity drift** — high-complexity modules with no recent refactor.
5. **TODO debt** — files with TODOs older than 2 sessions.

Each signal contributes a normalised score (0–100).  The overall priority
score is a weighted sum.  The output is a ranked queue of actions with
explicit rationale strings, so the operator (human or AI) knows *why* each
item is recommended.

No external dependencies — stdlib only.
"""

from __future__ import annotations

import json
import re
from dataclasses import dataclass, asdict, field
from pathlib import Path
from typing import Optional


# ---------------------------------------------------------------------------
# Data structures
# ---------------------------------------------------------------------------

@dataclass
class PredictionSignal:
    """One contributing signal for a prediction item."""

    name: str
    score: float      # 0–100, higher = more urgent
    weight: float
    rationale: str

    def weighted_score(self) -> float:
        """Compute the weight-adjusted score for this signal"""
        return self.score * self.weight


@dataclass
class PredictionItem:
    """A single recommended action for the next session."""

    rank: int
    action: str               # e.g. "Improve test coverage for security.py"
    target: str               # module / area name
    priority_score: float     # 0–100 overall
    signals: list[PredictionSignal]
    recommendation: str       # human-readable explanation
    suggested_command: str    # the awake command to run

    def to_dict(self) -> dict:
        """Return a dictionary representation of the prediction item"""
        return asdict(self)


@dataclass
class PredictionReport:
    """Full prediction report for the next session."""

    next_session: int
    items: list[PredictionItem]
    signals_used: list[str]
    session_count: int         # how many sessions of history were analysed
    generated_at: str

    @property
    def top_items(self) -> list[PredictionItem]:
        """Return the five highest-priority prediction items"""
        return self.items[:5]

    def to_dict(self) -> dict:
        """Return a dictionary representation of the prediction report"""
        return {
            "next_session": self.next_session,
            "items": [i.to_dict() for i in self.items],
            "signals_used": self.signals_used,
            "session_count": self.session_count,
            "generated_at": self.generated_at,
            "top_5": [i.to_dict() for i in self.top_items],
        }

    def to_json(self) -> str:
        """Serialize the prediction report to a JSON string"""
        return json.dumps(self.to_dict(), indent=2)

    def to_markdown(self) -> str:
        """Render the prediction report as a Markdown document"""
        lines: list[str] = []
        lines.append(f"# Predictive Session Planner — Session {self.next_session} Forecast\n")
        lines.append(f"**Sessions analysed:** {self.session_count}  ")
        lines.append(f"**Signals used:** {', '.join(self.signals_used)}  ")
        lines.append(f"**Generated:** {self.generated_at}\n")

        lines.append("## Top Recommendations\n")
        lines.append("| Rank | Target | Score | Action |")
        lines.append("|------|--------|-------|--------|")
        for item in self.items[:10]:
            lines.append(
                f"| #{item.rank} | `{item.target}` "
                f"| {item.priority_score:.0f}/100 | {item.action} |"
            )
        lines.append("")

        lines.append("## Detailed Analysis\n")
        for item in self.items[:7]:
            lines.append(f"### #{item.rank} — {item.action}")
            lines.append(f"**Priority score:** {item.priority_score:.0f}/100\n")
            lines.append(f"**Recommendation:** {item.recommendation}\n")
            lines.append(f"**Run:** `{item.suggested_command}`\n")
            if item.signals:
                lines.append("**Signals:**")
                for sig in item.signals:
                    lines.append(
                        f"- {sig.name}: {sig.score:.0f}/100 "
                        f"(weight {int(sig.weight*100)}%) — {sig.rationale}"
                    )
            lines.append("")

        lines.append("---")
        lines.append("*Predictions are generated by static analysis of session history.*")
        return "\n".join(lines)


# ---------------------------------------------------------------------------
# Session history parser
# ---------------------------------------------------------------------------

def _parse_session_log(log_path: Path) -> list[dict]:
    """Parse AWAKE_LOG.md into a list of session dicts."""
    if not log_path.exists():
        return []
    text = log_path.read_text(encoding="utf-8")
    # Extract session blocks by heading
    session_re = re.compile(
        r"## Session (\d+)[^\n]*\n(.*?)(?=## Session \d+|$)",
        re.DOTALL,
    )
    sessions = []
    for m in session_re.finditer(text):
        num = int(m.group(1))
        body = m.group(2)
        # Extract modules mentioned (src/*.py references)
        modules = re.findall(r"`src/([a-z_]+)\.py`", body)
        # Extract PR count from stats snapshot
        pr_match = re.search(r"Total PRs:\s*(\d+)", body)
        test_match = re.search(r"Test suite:\s*~?(\d+)", body)
        sessions.append({
            "session": num,
            "modules_touched": list(set(modules)),
            "total_prs": int(pr_match.group(1)) if pr_match else 0,
            "test_count": int(test_match.group(1)) if test_match else 0,
            "body": body,
        })
    return sorted(sessions, key=lambda s: s["session"])


def _get_all_modules(repo_path: Path) -> list[str]:
    """Return list of module names from src/*.py."""
    src = repo_path / "src"
    if not src.exists():
        return []
    return [
        p.stem for p in src.glob("*.py")
        if not p.stem.startswith("__")
    ]


def _last_session_touched(module: str, sessions: list[dict]) -> Optional[int]:
    """Return the last session number that touched *module*, or None."""
    for session in reversed(sessions):
        if module in session.get("modules_touched", []):
            return session["session"]
    return None


def _compute_age_signal(module: str, sessions: list[dict], latest_session: int) -> PredictionSignal:
    """Modules untouched for longer = higher urgency."""
    last = _last_session_touched(module, sessions)
    if last is None:
        age = latest_session  # never touched
        rationale = f"never mentioned in session log"
    else:
        age = latest_session - last
        rationale = f"last touched session {last} ({age} sessions ago)"
    # age 0 = just touched, age >= 5 = fully stale
    score = min(100.0, age * 20.0)
    return PredictionSignal(name="Module Age", score=score, weight=0.25, rationale=rationale)


def _compute_coverage_signal(module: str, repo_path: Path) -> PredictionSignal:
    """Modules with low test coverage get higher urgency."""
    try:
        from src.coverage_map import build_coverage_map
        cov = build_coverage_map(repo_path=repo_path)
        entry = next((e for e in cov.entries if e.module_name == module), None)
        if entry is None:
            return PredictionSignal(
                name="Coverage", score=60.0, weight=0.25,
                rationale="not in coverage map"
            )
        # Low coverage = high score (we want to fix low coverage)
        urgency = max(0.0, 100.0 - entry.score)
        return PredictionSignal(
            name="Coverage", score=urgency, weight=0.25,
            rationale=f"coverage score {entry.score:.0f}/100 "
                      f"({entry.test_count} tests, {entry.src_symbols} symbols)"
        )
    except Exception:
        return PredictionSignal(
            name="Coverage", score=50.0, weight=0.25,
            rationale="coverage analysis unavailable"
        )


def _compute_complexity_signal(module: str, repo_path: Path) -> PredictionSignal:
    """High-complexity modules with no recent refactor."""
    try:
        src_file = repo_path / "src" / f"{module}.py"
        if not src_file.exists():
            return PredictionSignal(name="Complexity", score=30.0, weight=0.20, rationale="file not found")
        import ast
        tree = ast.parse(src_file.read_text(encoding="utf-8"))
        # Rough complexity: count branches
        branch_nodes = (ast.If, ast.For, ast.While, ast.ExceptHandler, ast.With)
        branch_count = sum(1 for n in ast.walk(tree) if isinstance(n, branch_nodes))
        func_count = sum(1 for n in ast.walk(tree) if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef)))
        avg_branches = branch_count / max(func_count, 1)
        # avg > 5 = complex
        urgency = min(100.0, avg_branches * 12.0)
        return PredictionSignal(
            name="Complexity", score=urgency, weight=0.20,
            rationale=f"~{avg_branches:.1f} branches/function, {func_count} functions"
        )
    except Exception:
        return PredictionSignal(name="Complexity", score=30.0, weight=0.20, rationale="parse error")


def _compute_todo_signal(module: str, repo_path: Path) -> PredictionSignal:
    """Modules with TODOs get higher urgency."""
    try:
        src_file = repo_path / "src" / f"{module}.py"
        if not src_file.exists():
            return PredictionSignal(name="TODO Debt", score=0.0, weight=0.15, rationale="file not found")
        text = src_file.read_text(encoding="utf-8")
        todo_count = len(re.findall(r"#\s*(TODO|FIXME|HACK|XXX)", text, re.IGNORECASE))
        urgency = min(100.0, todo_count * 25.0)
        rationale = f"{todo_count} TODO/FIXME annotations"
        return PredictionSignal(name="TODO Debt", score=urgency, weight=0.15, rationale=rationale)
    except Exception:
        return PredictionSignal(name="TODO Debt", score=0.0, weight=0.15, rationale="read error")


def _compute_health_signal(module: str, sessions: list[dict]) -> PredictionSignal:
    """Infer health from session log mentions of fixes/refactors."""
    body_text = " ".join(s.get("body", "") for s in sessions[-3:])
    pattern = re.compile(
        rf"(fix|refactor|improve|clean|bug|error|issue)[^.]*{re.escape(module)}",
        re.IGNORECASE,
    )
    mentions = len(pattern.findall(body_text))
    # Many recent fix mentions = possibly problematic module
    urgency = min(100.0, mentions * 30.0)
    rationale = f"{mentions} fix/refactor mentions in last 3 sessions"
    return PredictionSignal(name="Health Trend", score=urgency, weight=0.15, rationale=rationale)


def _suggest_command(module: str, signals: list[PredictionSignal]) -> str:
    """Pick the most useful awake command for this module."""
    # Find the highest-urgency signal
    top_signal = max(signals, key=lambda s: s.weighted_score())
    if "Coverage" in top_signal.name:
        return f"awake coveragemap  # then add tests for {module}.py"
    if "Complexity" in top_signal.name:
        return f"awake refactor  # review {module}.py"
    if "TODO" in top_signal.name:
        return f"awake todos  # clear TODOs in {module}.py"
    if "Age" in top_signal.name:
        return f"awake health  # review {module}.py for improvements"
    return f"awake doctor  # general review of {module}.py"


def _build_recommendation(module: str, signals: list[PredictionSignal], score: float) -> str:
    top = max(signals, key=lambda s: s.weighted_score())
    urgency_word = "Critical" if score >= 75 else "High" if score >= 55 else "Medium"
    return (
        f"{urgency_word} priority. Primary driver: {top.name} — {top.rationale}. "
        f"Overall urgency score {score:.0f}/100."
    )


# ---------------------------------------------------------------------------
# Public API
# ---------------------------------------------------------------------------

def predict_next_session(repo_path: Path) -> PredictionReport:
    """Analyse session history and produce a ranked set of next-session actions."""
    import datetime

    log_path = repo_path / "AWAKE_LOG.md"
    sessions = _parse_session_log(log_path)
    latest_session = sessions[-1]["session"] if sessions else 0
    next_session = latest_session + 1

    modules = _get_all_modules(repo_path)
    if not modules:
        # Fallback if no src/ directory
        modules = ["(no modules found)"]

    items: list[PredictionItem] = []

    for module in modules:
        # Compute all signals
        age_sig = _compute_age_signal(module, sessions, latest_session)
        cov_sig = _compute_coverage_signal(module, repo_path)
        cx_sig = _compute_complexity_signal(module, repo_path)
        todo_sig = _compute_todo_signal(module, repo_path)
        health_sig = _compute_health_signal(module, sessions)

        sigs = [age_sig, cov_sig, cx_sig, todo_sig, health_sig]
        total_weight = sum(s.weight for s in sigs)
        priority = sum(s.weighted_score() for s in sigs) / total_weight if total_weight else 0.0

        # Determine action label
        top_sig = max(sigs, key=lambda s: s.weighted_score())
        if "Coverage" in top_sig.name:
            action = f"Improve test coverage for {module}.py"
        elif "Complexity" in top_sig.name:
            action = f"Refactor complex functions in {module}.py"
        elif "TODO" in top_sig.name:
            action = f"Resolve TODO debt in {module}.py"
        elif "Age" in top_sig.name:
            action = f"Review and update {module}.py (stale)"
        else:
            action = f"Investigate health trend in {module}.py"

        items.append(PredictionItem(
            rank=0,  # filled in below
            action=action,
            target=module,
            priority_score=round(priority, 1),
            signals=sigs,
            recommendation=_build_recommendation(module, sigs, priority),
            suggested_command=_suggest_command(module, sigs),
        ))

    # Sort by priority descending, assign ranks
    items.sort(key=lambda i: i.priority_score, reverse=True)
    for idx, item in enumerate(items, start=1):
        item.rank = idx

    return PredictionReport(
        next_session=next_session,
        items=items,
        signals_used=["Module Age", "Coverage Weakness", "Complexity Drift", "TODO Debt", "Health Trend"],
        session_count=len(sessions),
        generated_at=datetime.datetime.now().isoformat(timespec="seconds"),
    )


def save_prediction_report(report: PredictionReport, out_path: Path) -> None:
    """Write markdown + JSON sidecar."""
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(report.to_markdown(), encoding="utf-8")
    sidecar = out_path.with_suffix(".json")
    sidecar.write_text(report.to_json(), encoding="utf-8")
